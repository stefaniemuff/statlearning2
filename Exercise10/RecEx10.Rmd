---
title: 'Module 10: Recommended Exercises'
author:   
  - Emma Skarstein, Kenneth Aase, Daesoo Lee, Stefanie Muff, 
  - Department of Mathematical Sciences, NTNU
date: "March 23, 2023"
output:
   pdf_document:
     fig_caption: yes
     keep_tex: yes
     toc: no
     toc_depth: 2
   html_document:
    df_print: paged
    toc: no
    toc_depth: '2'
subtitle: TMA4268 Statistical Learning V2023
urlcolor: blue
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE,tidy=TRUE,message=FALSE,warning=FALSE,strip.white=TRUE,prompt=FALSE,
                      size="scriptsize",fig.width=4, fig.height=3,fig.align = "center")

```



# PCA on New York Times stories

This exercise is based on the New York Time stories example (code and data) on the [lecture](http://www.stat.cmu.edu/~cshalizi/490/10/) of Brian Junker and Cosma Shalizi about Principal components and factor analysis.

## Data Exploration

New stories were randomly selected from the [New York Times Annotated Corpus](https://catalog.ldc.upenn.edu/LDC2008T19). There are 57 stories about art and 45 about music on the dataset available. 

The `nyt_data` is a dataset containing these 102 stories, which represent the 102 observations. The first column contains class labels of the stories (art and music) and, and the other stories contain the counts of each word in a given story (weight by the inverse document frequency and normalized by vector length).

The New York Times stories dataset are contained in the file `pca-exampes.rdata`, which you can load from google drive (https://drive.google.com/open?id=1vaK9GDvMw4Hsuv0T1jHeq9ZyrqLhJ6MR) and store in the directory of your Rmd file. The pca-examples.rdata can be loaded with the following code.

```{r, eval = T}
load("pca-examples.rdata")

# We will work with nyt.frame
nyt_data = nyt.frame
```


```{r, echo=T, eval=F}
str(nyt_data)
summary(nyt_data$class.labels)
```

Let's check some word samples:

```{r, message=FALSE, warning=FALSE}
colnames(nyt_data)[sample(ncol(nyt_data),30)]
```

Let's check some values in the dataset. We have many zeroes, as most words do not appear in most stories.

```{r, message=FALSE, warning=FALSE}
signif(nyt_data[sample(nrow(nyt_data),5),sample(ncol(nyt_data),10)],3)
```




# Problem 1



- For the New York Times stories (`nyt_data`) dataset:
    - Create a biplot and explain the type of information that you can extract from the plot.
    - Create plots for the proportion of variance explained (PVE) and cumulative PVE. Describe what type of information you can extract from the plots.
    


# Problem 2

Show that the algorithm below is guaranteed to decrease the value of the objective

$$\underset{C_1, \ldots, C_k}{\text{minimize}}\left\{\sum_{k=1}^{K} \frac{1}{|C_k|} \sum_{i, i' \in C_k} \sum_{j=1}^{p}(x_{ij} - x_{i'j})^2 \right\}$$

at each step. 

\center
![](kmeans_algo.pdf){width='80%'}

\flushleft

# Problem 3

Perform $k$-means clustering in the New York Times stories dataset. 


# Problem 4

Perform hierarchical clustering in the New York Times stories dataset. 

